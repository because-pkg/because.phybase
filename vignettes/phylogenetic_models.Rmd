---
title: "phybaseR: An R package to easily create and run PhyBaSE models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{phybaseR: An R package to easily create and run PhyBaSE models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

**phybaseR** is an R package designed to easily perform causal inference in phylogenetic comparative analyses implementing and extending the methods proposed in von Hardenberg & Gonzalez-Voyer (2025). It allows you to fit Phylogenetic Bayesian Structural Equation Models (SEMs) that account for:

*   **Phylogenetic Non-independence**: Using the phylogenetic covariance matrix.
*   **Measurement Error**: Incorporating standard errors or repeated measures.
*   **Missing Data**: Automatically handling missing values in both predictors and responses.
*   **Phylogenetic Uncertainty**: Integrating over a posterior sample of trees.
*   **Multiple Response Distributions**: 
    - Gaussian (continuous data)
    - Binomial (binary/proportion data)
    - Multinomial (unordered categorical data)
    - Ordinal (ordered categorical data)
    - Poisson (count data)
    - Negative Binomial (overdispersed count data)
*   **Categorical Predictors**: Automatic handling of factor variables with dummy coding.
*   **Optimized Performance**: Fast random effects formulation (4.6× speedup) for large datasets.
*   **Flexible Data Input**: Pass data as a `.data.frame` (recommended) or a named `list`. When using a phylogenetic tree or other external covariance structure, specify `id_col` to match data rows to the structure tips/dimensions. For standard random effects models, `id_col` is not required.

This tutorial will guide you through the main features of the package.


## Setup

First, load the package:

```{r setup}
library(phybaseR)
```

**Note**: `phybaseR` uses `ape` internally for phylogenetic calculations (it's automatically loaded as a dependency). We'll also load it explicitly here for the tutorial examples, since we use `ape` functions like `rtree()` and `rTraitCont()` to simulate data:

```{r load_ape}
library(ape)
```

**Note on Tree Standardization**: `phybaseR` automatically standardizes phylogenetic trees to have a maximum branching time of 1.0. This improves numerical stability and convergence. You'll see a message like "Standardizing tree edge lengths (max branching time: 1.27 -> 1.0)" when this occurs. This doesn't affect your results—it's just internal scaling.

## Basic Usage: Phylogenetic Regression (PGLS)

Let's start with a simple example: a phylogenetic regression of `Y` on `X`. We'll simulate some data for demonstration.

```{r basic_sim}
set.seed(123)
N <- 50
tree <- rtree(N)

# Simulate traits and create a data.frame
my_data <- data.frame(
    species = tree$tip.label,
    X = rTraitCont(tree, model = "BM", sigma = 1),
    Y = 0.5 + 0.8 * rTraitCont(tree, model = "BM", sigma = 1) +
        rTraitCont(tree, model = "BM", sigma = 0.5)
)
```

To run the model, we define the structural equations and pass them to `phybase_run()`. Note that we can pass a data.frame directly—phybaseR will automatically extract the needed variables from your equations:

```{r basic_run, eval=FALSE}
# Define equations
equations <- list(Y ~ X)

# Run model - pass the data.frame directly!
fit <- phybase_run(
    data = my_data,
    id_col = "species", # Column with species names
    tree = tree,
    equations = equations,
    n.iter = 5000,
    n.burnin = 1000,
    n.chains = 3
)

# View summary
summary(fit)
```

## Mediation Analysis

PhyBaSE shines at testing causal paths, such as mediation: `X -> M -> Y`.

```{r mediation_sim}
# Simulate mediator M
M <- 0.3 + 0.6 * my_data$X + rTraitCont(tree, model = "BM", sigma = 0.5)
# Simulate Y affected by both X and M
Y_med <- 0.5 + 0.4 * my_data$X + 0.5 * M + rTraitCont(tree, model = "BM", sigma = 0.5)

# Create data.frame with all variables
med_data <- data.frame(
    species = tree$tip.label,
    X = my_data$X,
    M = M,
    Y = Y_med
)
```

```{r mediation_run, eval=FALSE}
# Define DAG equations
equations_med <- list(
    M ~ X,
    Y ~ X + M
)

fit_med <- phybase_run(
    data = med_data,
    id_col = "species",
    tree = tree,
    equations = equations_med
)

summary(fit_med)
```

## Understanding Parameter Names

`phybaseR` uses a systematic naming convention for all estimated parameters. Understanding this helps you interpret your results.

### Regression Coefficients

**Format**: `beta_Response_Predictor` (consistent for all models)

- `beta_Y_X` - Effect of X on Y in model `Y ~ X`
- `beta_Y_M` - Effect of M on Y in model `Y ~ X + M`

**Special cases**:
- **Multinomial/Ordinal**: `beta_Response_Predictor[k]` - Effect on category k (k ≥ 2)
- **Intercepts**: Always named `alpha_Response` or `alpha_Response[k]` for categorical responses

**Naming convention**: 
- `alpha` = intercepts
- `beta` = regression coefficients (slopes)

### Phylogenetic Signal

**Format**: `lambda_Variable` or `lambdaVariable`

- `lambdaX` - Pagel's λ for variable X (0 = no signal, 1 = Brownian motion)
- `lambda_Multi[k]`- Phylogenetic signal in category k of multinomial response

**Range**: 0 to 1
- **0** = No phylogenetic signal (pure residual variance)
- **1** = Full Brownian motion (pure phylogenetic variance)
- **0.5** = Equal phylogenetic and residual variance

### Variance Components

**Precision parameters** (inverse of variance):

- `tau_Variable` or `tauVariable` - Overall precision (older parameter name)
- `tau_u_Variable` - **Phylogenetic** precision (1 / phylogenetic variance)
- `tau_e_Variable` - **Residual** precision (1 / residual variance)

**Relationship**: Higher precision = Lower variance = Less uncertainty

**For categorical responses** (multinomial, ordinal):
- `tau_u_Response[k]` - Phylogenetic precision for category k
- `tau_e_Response[k]` - Residual precision for category k

### Ordinal-Specific Parameters

- `cutpoint_Response[j]` - Threshold between categories j and j+1
  - Example: `cutpoint_IUCN[1]` separates LC from NT

### Examples in Context

```r
# Model: Y ~ X + M
equations <- list(Y ~ X + M)

# Key output parameters:
# alphaY         - Intercept for Y
# beta_Y_X       - Effect of X on Y (focal parameter)
# beta_Y_M       - Effect of M on Y (focal parameter)
# lambdaY        - Phylogenetic signal in Y
# tau_u_Y, tau_e_Y - Variance components for Y
```

### Auxiliary Parameters for Predictors

If your model includes **missing values in predictors** or requires modeling **phylogenetic structure in predictors**, phybaseR automatically adds implicit equations (e.g., `X ~ 1`). This results in additional parameters:

```r
# Example: Y ~ X with missing values in X
# Implicit equation X ~ 1 is added automatically

# You'll see these EXTRA parameters:
# alphaX         - Mean of X (auxiliary, not usually interpreted)
# lambdaX        - Phylogenetic signal in X
# tau_u_X, tau_e_X - Variance components for X
```

**When this happens**:
- ✅ Missing data in any predictor
- ✅ Predictors with phylogenetic signal that needs to be accounted for

**Interpretation**: Focus on `beta` coefficients and `lambda` for responses. The auxiliary predictor parameters are needed for the model to work correctly but are rarely the focus of biological interpretation.

### Controlling Output with `monitor` Modes

For cleaner output, use the `monitor` parameter to control which parameters are shown:

```r
# Default: "interpretable" mode - shows only meaningful parameters
fit <- phybase_run(
  data = data_list,
  tree = tree,
  equations = equations,
  monitor = "interpretable"  # or just omit (default)
)

# Output includes:
# - alphas (intercepts)
# - betas (regression coefficients)  
# - lambdas for RESPONSES only
# But EXCLUDES:
# - taus (variance components)
# - lambdas for auxiliary predictors

# To see ALL parameters including variance components:
fit_complete <- phybase_run(
  data = data_list,
  tree = tree,
  equations = equations,
  monitor = "all"  # Complete output
)

# Custom monitoring (advanced):
fit_custom <- phybase_run(
  data = data_list,
  tree = tree,
  equations = equations,
  monitor = c("beta_Y_X", "lambdaY", "alphaY")  # Specific parameters
)
```

## Measurement Error

PhyBaSE can account for measurement error in your variables.

### Option 1: Using Standard Errors (SE)

If you have known standard errors for your species means:

```{r me_se, eval=FALSE}
# Assume we have SEs for X
X_se <- rep(0.1, N)
data_se <- list(X = X, Y = Y, X_se = X_se)

fit_se <- phybase_run(
    data = data_se,
    tree = tree,
    equations = list(Y ~ X),
    variability = c(X = "se") # Tell PhyBaSE that X has SEs
)

summary(fit_se)
```

**Note on DIC with measurement error**: When using measurement error (either SE or repeated measures), the DIC penalty will be inflated because PhyBaSE creates latent "true" values for each species. The penalty will be approximately: structural parameters + N (number of species). This is expected behavior.

- For **model comparison**, use WAIC instead: `phybase_run(..., WAIC = TRUE)`
- For **fit quality**, focus on the mean deviance (lower is better)
- The inflated penalty does not affect the validity of the model, only the DIC interpretation

### Option 2: Using Repeated Measures

If you have raw data (multiple observations per species), PhyBaSE can estimate the observation error directly.

```{r me_reps, eval=FALSE}
# Simulate unequal repeated measures (ragged array)
# Some species have 2 reps, some have 3
max_reps <- 3
X_obs <- matrix(NA, nrow = N, ncol = max_reps)

for (i in 1:N) {
    # Randomly decide if species has 2 or 3 reps
    n_i <- sample(2:3, 1)

    # Simulate data
    vals <- rnorm(n_i, mean = X[i], sd = 0.2)

    # Fill matrix (padding with NA for missing reps)
    X_obs[i, 1:n_i] <- vals
}

fit_reps <- phybase_run(
    data = list(X = X_obs, Y = Y),
    tree = tree,
    equations = list(Y ~ X),
    variability = c(X = "reps")
)

summary(fit_reps)

# PhyBaSE automatically handles the NAs and counts valid replicates per species.
```

## Binomial Variables

You can model binary traits (binomial) using a phylogenetic logistic regression framework.

```{r binomial, eval=FALSE}
# Simulate binary trait
prob <- 1 / (1 + exp(-(0.5 + 0.8 * X)))
BinaryTrait <- rbinom(N, 1, prob)

data_bin <- list(X = X, Bin = BinaryTrait)

fit_bin <- phybase_run(
    data = data_bin,
    tree = tree,
    equations = list(Bin ~ X),
    distribution = c(Bin = "binomial"), # Specify distribution
    WAIC = TRUE, # Use WAIC for model comparison (recommended for non-Gaussian models)
    DIC = FALSE # DIC may produce NaN penalty with latent variable models
)

summary(fit_bin)
```

**Note on Model Comparison**: For binomial (and other non-Gaussian) models, DIC may produce `NaN` values for penalty because JAGS's `dic.samples()` doesn't handle latent variable models well. **Use WAIC instead** (`WAIC = TRUE`) for reliable model comparison with binomial, multinomial, ordinal, Poisson, and Negative Binomial distributions.

**Note**: Binomial variables should generally be child nodes (responses) in your DAG.


## Multinomial Variables

For categorical traits with more than two unordered levels (e.g., diet type: Carnivore, Herbivore, Omnivore), you can use the multinomial distribution.

```{r multinomial, eval=FALSE}
# Simulate multinomial trait with phylogenetic signal (3 categories)
# Example: Diet type (Carnivore, Herbivore, Omnivore)
library(MASS)

VCV <- ape::vcv.phylo(tree)

# Phylogenetically structured errors for categories 2 and 3
# (category 1 is the reference)
lambda_2 <- 0.6 # Phylogenetic signal for category 2
tau_u_2 <- 1 / 0.5
tau_e_2 <- 1 / 0.3
u_std_2 <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
err_2 <- u_std_2 / sqrt(tau_u_2) + rnorm(N, 0, sqrt(1 / tau_e_2))

lambda_3 <- 0.7 # Phylogenetic signal for category 3
tau_u_3 <- 1 / 0.5
tau_e_3 <- 1 / 0.3
u_std_3 <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
err_3 <- u_std_3 / sqrt(tau_u_3) + rnorm(N, 0, sqrt(1 / tau_e_3))

# Latent utilities for each category (with phylogenetic signal)
L1 <- rep(0, N) # Reference category (Carnivore)
L2 <- -1 + 0.5 * X + err_2 # Category 2 (Herbivore)
L3 <- 1 - 0.5 * X + err_3 # Category 3 (Omnivore)

# Softmax transformation to get probabilities
exp_L1 <- exp(L1)
exp_L2 <- exp(L2)
exp_L3 <- exp(L3)
sum_exp <- exp_L1 + exp_L2 + exp_L3

P1 <- exp_L1 / sum_exp # P(Carnivore)
P2 <- exp_L2 / sum_exp # P(Herbivore)
P3 <- exp_L3 / sum_exp # P(Omnivore)

# Sample multinomial outcome
MultiTrait <- apply(cbind(P1, P2, P3), 1, function(p) sample(1:3, 1, prob = p))

data_multi <- list(X = X, Multi = MultiTrait) # K is auto-detected

fit_multi <- phybase_run(
    data = data_multi,
    tree = tree,
    equations = list(Multi ~ X),
    distribution = c(Multi = "multinomial"),
    optimise = TRUE
)

summary(fit_multi)

# Check recovery of phylogenetic signal for each category
# lambda parameters should be ~ 0.6 and 0.7
fit_multi$summary$statistics[grep("lambda", rownames(fit_multi$summary$statistics)), ]
```

**Note**: The summary will show parameters for each category $k \ge 2$ (e.g., `beta_Multi_X[2]`, `beta_Multi_X[3]`), relative to the reference category $k=1$. Key parameters to interpret:
- `beta_Multi_X[k]` - Effects of X on each category 
- `lambda_Multi[k]` - Phylogenetic signal in each category

## Ordinal Variables

For **ordered categorical data** (e.g., IUCN Red List categories: LC < NT < VU < EN < CR), use the ordinal distribution. This respects the ordering of categories and is more appropriate than multinomial for such data.

```{r ordinal, eval=FALSE}
# Simulate IUCN-like conservation status with phylogenetic signal
# DAG: BodyMass -> IUCN <- HabitatLoss
#      BodyMass -> HabitatLoss
# Implied independence: IUCN ⊥ BodyMass | HabitatLoss
library(MASS)

# Phylogenetically structured predictors
VCV <- ape::vcv.phylo(tree)

# Body Mass (exogenous)
lambda_mass <- 0.6
Sigma_mass <- lambda_mass * VCV + (1 - lambda_mass) * diag(N)
BodyMass <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = Sigma_mass))

# Habitat Loss (caused by body mass)
lambda_habitat <- 0.5
tau_u_habitat <- 1 / 0.4
tau_e_habitat <- 1 / 0.3
u_std_habitat <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
HabitatLoss <- 1.2 + 0.7 * BodyMass + u_std_habitat / sqrt(tau_u_habitat) +
    rnorm(N, 0, sqrt(1 / tau_e_habitat))

# IUCN status (ordinal response, caused by both predictors)
lambda_IUCN <- 0.75
tau_u_IUCN <- 1 / 0.5
tau_e_IUCN <- 1 / 0.3
u_std_IUCN <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
phylo_error <- u_std_IUCN / sqrt(tau_u_IUCN) + rnorm(N, 0, sqrt(1 / tau_e_IUCN))

# Linear predictor: larger mass + more habitat loss -> higher threat
eta <- -0.5 * BodyMass + 0.8 * HabitatLoss + phylo_error
cutpoints <- c(-1, 0, 1, 2) # Thresholds between categories

# Calculate probabilities using cumulative logit
Q <- matrix(0, nrow = N, ncol = 4)
for (i in 1:N) {
    for (k in 1:4) {
        Q[i, k] <- 1 / (1 + exp(-(cutpoints[k] - eta[i])))
    }
}

# Category probabilities
P <- matrix(0, nrow = N, ncol = 5)
P[, 1] <- Q[, 1]
for (k in 2:4) {
    P[, k] <- Q[, k] - Q[, k - 1]
}
P[, 5] <- 1 - Q[, 4]

# Sample ordinal outcome (1=LC, 2=NT, 3=VU, 4=EN, 5=CR)
IUCN <- apply(P, 1, function(p) sample(1:5, 1, prob = p))

data_ordinal <- list(
    BodyMass = BodyMass,
    HabitatLoss = HabitatLoss,
    IUCN = IUCN,
    K_IUCN = 5
)

# Fit the DAG
fit_ordinal <- phybase_run(
    data = data_ordinal,
    tree = tree,
    equations = list(
        IUCN ~ BodyMass + HabitatLoss,
        HabitatLoss ~ BodyMass
    ),
    distribution = c(IUCN = "ordinal"),
    optimise = TRUE
)

summary(fit_ordinal)

# Check recovery of phylogenetic signal
fit_ordinal$summary$statistics["lambdaIUCN", ]

# Test d-separation: IUCN ⊥ BodyMass | HabitatLoss
fit_dsep <- phybase_run(
    data = data_ordinal,
    tree = tree,
    equations = list(
        IUCN ~ BodyMass + HabitatLoss,
        HabitatLoss ~ BodyMass
    ),
    distribution = c(IUCN = "ordinal"),
    dsep = TRUE,
    optimise = TRUE
)

# Check if betaBodyMass is close to zero in the d-sep test
summary(fit_dsep$samples)
# If 95% CI of betaBodyMass includes zero -> independence supported
```


**Key advantages of ordinal over multinomial**:
- Respects category ordering (statistical validity)
- More parsimonious (fewer parameters)
- Easier interpretation (single $\beta$ coefficient, not $K-1$)

**Note**: You'll see estimated cutpoints in the output (`cutpoint_IUCN[1]`, `cutpoint_IUCN[2]`, etc.), which define the thresholds between adjacent categories.

## Poisson Variables (Count Data)

For **count data** (e.g., clutch size, litter size, number of vertebrae), use the Poisson distribution. These **meristic traits** are countable morphological or life-history features that show phylogenetic signal. The random effects formulation naturally handles **overdispersion** via the residual variance component.

```{r poisson, eval=FALSE}
# Simulate count data with phylogenetic signal
# Example: Clutch size (number of eggs) in birds
# DAG: BodyMass -> ClutchSize <- Latitude
#      BodyMass -> Latitude
# Implied independence: ClutchSize ⊥ BodyMass | Latitude
library(MASS)

# Phylogenetically structured predictors
VCV <- ape::vcv.phylo(tree)

# Body mass (log-scale, exogenous)
lambda_bm <- 0.8
Sigma_bm <- lambda_bm * VCV + (1 - lambda_bm) * diag(N)
BodyMass <- as.vector(mvrnorm(1, mu = rep(4, N), Sigma = Sigma_bm))

# Latitude (caused by body mass - Bergmann's rule proxy)
lambda_lat <- 0.6
tau_u_lat <- 1 / 0.4
tau_e_lat <- 1 / 0.3
u_std_lat <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
Latitude <- 30 - 0.4 * BodyMass + u_std_lat / sqrt(tau_u_lat) +
    rnorm(N, 0, sqrt(1 / tau_e_lat))

# Phylogenetically structured error term for clutch size
lambda_clutch <- 0.7 # True phylogenetic signal in clutch size
tau_u <- 1 / 0.5 # Phylogenetic variance
tau_e <- 1 / 0.3 # Residual variance
u_std <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
u <- u_std / sqrt(tau_u)
epsilon <- rnorm(N, 0, sqrt(1 / tau_e))
phylo_error <- u + epsilon

# True model: log(E[ClutchSize]) = 1.5 + 0.03*Latitude + phylo_error
# Larger clutches at higher latitudes, body mass affects ONLY through latitude
log_clutch <- 1.5 + 0.03 * Latitude + phylo_error
ClutchSize <- rpois(N, lambda = exp(log_clutch))

data_poisson <- list(
    BodyMass = BodyMass,
    Latitude = Latitude,
    ClutchSize = ClutchSize
)

# Fit the DAG
fit_poisson <- phybase_run(
    data = data_poisson,
    tree = tree,
    equations = list(
        ClutchSize ~ Latitude,
        Latitude ~ BodyMass
    ),
    distribution = c(ClutchSize = "poisson"),
    optimise = TRUE
)

summary(fit_poisson)

# Check recovery of phylogenetic signal
# lambdaClutchSize should be ~ 0.7
fit_poisson$summary$statistics["lambdaClutchSize", ]

# Test d-separation: ClutchSize ⊥ BodyMass | Latitude
fit_dsep <- phybase_run(
    data = data_poisson,
    tree = tree,
    equations = list(
        ClutchSize ~ Latitude,
        Latitude ~ BodyMass
    ),
    distribution = c(ClutchSize = "poisson"),
    dsep = TRUE,
    optimise = TRUE
)

# Check if betaBodyMass is close to zero in the d-sep test
summary(fit_dsep$samples)
# If 95% CI of betaBodyMass includes zero -> independence supported
```

**Overdispersion handling**: Unlike standard Poisson GLMs, the random effects formulation includes `tau_e` (residual precision), which absorbs extra-Poisson variation. This makes it equivalent to a **quasi-Poisson** model without needing an explicit overdispersion parameter.

**When to use Poisson vs. Negative Binomial**:
- **Poisson**: Default for count data; handles moderate overdispersion
- **Negative Binomial**: Heavy overdispersion (variance >> mean)

## Negative Binomial Variables (Overdispersed Counts)

For **heavily overdispersed count data** where variance far exceeds the mean, use the Negative Binomial distribution. It includes an explicit **size parameter** (`r`) that controls overdispersion.

```{r negbinomial, eval=FALSE}
# Simulate heavily overdispersed count data with phylogenetic signal
# DAG: HostSize -> Parasites <- Stress
#      HostSize -> Stress
# Implied independence: Parasites ⊥ HostSize | Stress
library(MASS)

# Phylogenetically structured predictors
VCV <- ape::vcv.phylo(tree)

# Host Size (exogenous)
lambda_size <- 0.4
Sigma_size <- lambda_size * VCV + (1 - lambda_size) * diag(N)
HostSize <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = Sigma_size))

# Stress (caused by host size)
lambda_stress <- 0.5
tau_u_stress <- 1 / 0.4
tau_e_stress <- 1 / 0.3
u_std_stress <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
Stress <- 1.5 + 0.6 * HostSize + u_std_stress / sqrt(tau_u_stress) +
    rnorm(N, 0, sqrt(1 / tau_e_stress))

# Phylogenetically structured error term for parasites
lambda_parasites <- 0.8 # True phylogenetic signal
tau_u <- 1 / 0.6
tau_e <- 1 / 0.4
u_std <- as.vector(mvrnorm(1, mu = rep(0, N), Sigma = solve(VCV)))
u <- u_std / sqrt(tau_u)
epsilon <- rnorm(N, 0, sqrt(1 / tau_e))
phylo_error <- u + epsilon

# True model with overdispersion
# Stress increases parasite load (HostSize affects load ONLY through Stress)
r_true <- 2 # Size parameter (smaller = more overdispersed)
log_mu <- 2 + 0.7 * Stress + phylo_error
mu <- exp(log_mu)
parasite_count <- rnbinom(N, size = r_true, mu = mu)

data_nb <- list(
    HostSize = HostSize,
    Stress = Stress,
    Parasites = parasite_count
)

# Fit the DAG
fit_nb <- phybase_run(
    data = data_nb,
    tree = tree,
    equations = list(
        Parasites ~ Stress,
        Stress ~ HostSize
    ),
    distribution = c(Parasites = "negbinomial"),
    optimise = TRUE
)

summary(fit_nb)

# Check recovery of phylogenetic signal
# lambdaParasites should be ~ 0.8
fit_nb$summary$statistics["lambdaParasites", ]

# Test d-separation: Parasites ⊥ HostSize | Stress
fit_dsep <- phybase_run(
    data = data_nb,
    tree = tree,
    equations = list(
        Parasites ~ Stress,
        Stress ~ HostSize
    ),
    distribution = c(Parasites = "negbinomial"),
    dsep = TRUE,
    optimise = TRUE
)

# Check if betaHostSize is close to zero in the d-sep test
summary(fit_dsep$samples)
# If 95% CI of betaHostSize includes zero -> independence supported
```

**Understanding the size parameter (`r`)**:
- **Smaller `r`** → More overdispersion (variance >> mean)
- **Larger `r`** → Less overdispersion (approaches Poisson)
- **Typical values**: r = 0.5-5 for heavily overdispersed biological data

```
**Poisson vs. Negative Binomial decision tree**:
1. **Variance ≈ Mean**: Use Poisson (simpler, fewer parameters)
2. **Variance > Mean** (2-5x): Poisson with random effects (handles it via `tau_e`)
3. **Variance >> Mean** (>5x): Negative Binomial (explicit overdispersion modeling)

## Categorical Predictors

`phybaseR` automatically handles categorical predictors (factor or character variables) by converting them to **dummy variables** and **auto-expanding** equations.

```{r categorical, eval=FALSE}
# Data with categorical predictor
data <- data.frame(
    Species = tree$tip.label,
    BodyMass = rnorm(N),
    Diet = sample(c("Carnivore", "Herbivore", "Omnivore"), N, replace = TRUE),
    Habitat = factor(sample(c("Forest", "Grassland"), N, replace = TRUE))
)

# phybase_format_data automatically creates dummy variables
data_list <- phybase_format_data(data, tree = tree)
# Messages:
# Categorical variable 'Diet' expanded to 2 dummy variable(s) | Reference: 'Carnivore'
# Categorical variable 'Habitat' expanded to 1 dummy variable(s) | Reference: 'Forest'

# Use categorical variables DIRECTLY in equations - auto-expands!
fit <- phybase_run(
    data = data_list,
    tree = tree,
    equations = list(BodyMass ~ Diet + Habitat) # Auto-expands to dummies!
)
# Messages:
# Expanded 'Diet' to: Diet_Herbivore, Diet_Omnivore
# Expanded 'Habitat' to: Habitat_Grassland

summary(fit)
```

**Key points**:
- **Auto-expansion**: Write `Y ~ Diet`, get `Y ~ Diet_Herbivore + Diet_Omnivore`
- **Reference category**: First level alphabetically (e.g., "Carnivore" for Diet)
- **K-1 encoding**: K levels → K-1 dummy variables
- **Interpretation**: Coefficients are effects relative to reference category

**Example interpretation**:
- `beta_BodyMass_Diet_Herbivore = -0.65` → Herbivores 0.65 units lighter than Carnivores
- `beta_BodyMass_Habitat_Grassland = 0.56` → Grassland species 0.56 units heavier than Forest

## Missing Data

PhyBaSE fully supports missing data (`NA`) in both response and predictor variables. It uses a **Latent Variable (GLMM)** approach to impute missing values while preserving phylogenetic signal.

```{r missing, eval=FALSE}
# Introduce missing values
X_miss <- X
X_miss[c(1, 5, 10)] <- NA # Missing in predictor
Y_miss <- Y
Y_miss[c(2, 6, 12)] <- NA # Missing in response

data_miss <- list(X = X_miss, Y = Y_miss)

# Just run it! No extra setup needed.
fit_miss <- phybase_run(
    data = data_miss,
    tree = tree,
    equations = list(Y ~ X)
)

summary(fit_miss)

# PhyBaSE automatically detects NAs and handles them.
```

## Phylogenetic Uncertainty

To account for uncertainty in the phylogeny itself, simply pass a list of trees (e.g., a `multiPhylo` object) instead of a single tree.

```{r multitree, eval=FALSE}
# For demonstration, simulate multiple trees
num_trees <- 20
trees <- lapply(1:num_trees, function(x) rtree(N))

fit_multi <- phybase_run(
    data = data_list,
    tree = trees, # Pass list of trees
    equations = equations
)

summary(fit_multi)
```

## Parallel Execution

Running MCMC chains in parallel can significantly speed up your analysis, especially for complex models or when using many iterations.

### Parallel Chains

To run chains in parallel, simply set `parallel = TRUE` and specify the number of cores with `n.cores`.

```{r parallel, eval=FALSE}
fit_parallel <- phybase_run(
    data = data_list,
    tree = tree,
    equations = equations,
    n.iter = 10000,
    n.chains = 4,
    parallel = TRUE,
    n.cores = 4 # Use 4 cores for 4 chains
)
```

**Note**: When running in parallel, DIC and WAIC calculation requires a brief model recompilation step (enabled by default with `ic_recompile = TRUE`). This ensures you still get model comparison metrics.

### Parallel Model Comparison

If you have a list of models to compare, you can run them all in parallel using `phybase_compare()`.

```{r parallel_compare, eval=FALSE}
# Define multiple models
models <- list(
    model1 = list(equations = list(Y ~ X)),
    model2 = list(equations = list(Y ~ 1)) # Null model
)

# Run all models in parallel
results <- phybase_compare(
    models = models,
    data = data_list,
    tree = tree,
    n.iter = 5000,
    n.cores = 2 # Run 2 models at a time
)

# Compare WAIC
print(results$comparison)
```

## Model Comparison (WAIC with Standard Errors)

The Widely Applicable Information Criterion (WAIC) is the recommended approach for model comparison in `phybaseR`. The package implements **WAIC with standard errors** following Vehtari, Gelman & Gabry (2017), allowing you to assess whether model differences are statistically significant.

### Calculating WAIC

Set `WAIC = TRUE` in `phybase_run()` to calculate WAIC with standard errors automatically:

```{r waic_example, eval=FALSE}
fit <- phybase_run(
    data = data,
    structure = tree,
    id_col = "SP",
    equations = list(Y ~ X),
    WAIC = TRUE, # Enable WAIC calculation
    n.chains = 2, # At least 2 chains recommended
    n.iter = 2000
)

# View WAIC results with standard errors
fit$WAIC
#            Estimate   SE
# elpd_waic   -617.3  12.4
# p_waic        12.3   3.1
# waic        1234.5  24.8
```

**Output interpretation**:
- `elpd_waic`: Expected log pointwise predictive density (higher is better)
- `p_waic`: Effective number of parameters
- `waic`: Widely Applicable Information Criterion (lower is better)
- `SE`: Standard error for each metric

### Comparing Models

Compare fitted models using `phybase_compare()`, which returns a ranked table with WAIC, standard errors, differences, and Akaike weights.

#### Option 1: Compare Fitted Models

```{r waic_comparison, eval=FALSE}
# Fit competing models
fit_complex <- phybase_run(..., WAIC = TRUE)
fit_simple <- phybase_run(..., WAIC = TRUE)

# Compare results
comp <- phybase_compare(fit_complex, fit_simple)
print(comp)

# Output:
#              WAIC   SE dWAIC  dSE p_waic weight
# fit_complex 212.8 12.4   0.0  0.0   12.3  0.98
# fit_simple  220.0 11.8   7.2  3.1   10.5  0.02
```

**Interpretation**:
- **dWAIC**: Difference from the best model.
- **dSE**: Standard error of the difference. A difference is significant if `|dWAIC| > 2 * dSE`.
- **weight**: Probability that the model is the best among the set.

#### Option 2: Run and Compare in Parallel

You can also specify multiple models and run them in parallel (this automatically enables WAIC):

```{r batch_comparison, eval=FALSE}
# Define model specifications
specs <- list(
    Full = list(equations = list(Y ~ X1 + X2)),
    Reduced = list(equations = list(Y ~ X1)),
    Null = list(equations = list(Y ~ 1))
)

# Run batch in parallel
results <- phybase_compare(
    model_specs = specs,
    data = data,
    tree = tree,
    n.cores = 3 # Parallel execution
)

# View comparison table
print(results$comparison)
```

### Notes on Comparison

- **At least 2 chains**: WAIC requires `n.chains >= 2` for reliable standard errors
- **Sufficient samples**: Use at least n.iter = 1000 (preferably 2000+) for stable SE estimates
- **Lower is better**: Choose the model with the lowest WAIC
- **Pointwise storage**: Pointwise log-likelihoods are automatically stored for detailed model diagnostics
- **All distributions supported**: Works with Gaussian, Poisson, Binomial, NegBin, Ordinal, Multinomial

**Reference**: Vehtari, A., Gelman, A. & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. *Statistics and Computing*, 27(5), 1413-1432.


## Model Validation (d-separation)

You can validate your model structure by testing the conditional independence statements implied by your DAG. This is done using the d-separation (basis set) method.

```{r dsep_example, eval=FALSE}
# Define a path model: A -> B -> C
# This implies: A is independent of C, conditional on B
A <- rTraitCont(tree)
B <- 0.5 + 0.8 * A + rTraitCont(tree)
C <- 0.5 + 0.8 * B + rTraitCont(tree)

dsep_data <- data.frame(
    species = tree$tip.label,
    A = A, B = B, C = C
)

equations_dsep <- list(
    B ~ A,
    C ~ B
)

# Run d-separation tests by setting dsep = TRUE
fit_dsep <- phybase_run(
    data = dsep_data,
    id_col = "species",
    tree = tree,
    equations = equations_dsep,
    dsep = TRUE # <--- This triggers d-sep testing
)

# The summary will show the conditional independence tests
summary(fit_dsep)
```

### Note on Sequential Testing

In the original PhyBaSE methodology (von Hardenberg & Gonzalez-Voyer, 2025), d-separation tests were proposed to be run within a single JAGS model by renaming variables (e.g., `BM`, `BM2`) to avoid cyclic dependencies in the Directed Acyclic Graph (DAG). 

`phybaseR` automates this process by running each d-separation test **sequentially** as a separate JAGS model. This approach offers several advantages for automation:

1.  **Computational Robustness**: It completely avoids cyclic dependency errors (e.g., "Unable to resolve parameter") that can occur in JAGS when multiple conditional independence tests imply conflicting directions of causality (e.g., testing $X \perp Y | Z$ and $Y \perp X | W$ simultaneously).
2.  **Statistical Validity**: D-separation tests are tests of *local* conditional independence. Running them sequentially is statistically valid because each test evaluates a specific implication of the DAG using the observed data.
3.  **Local Imputation**: For datasets with missing values, this approach implies that imputation is performed "locally" for each test based on the variables included in that specific test's conditioning set (plus the phylogeny). This is a standard and valid approach for piecewise SEM, ensuring that each test correctly propagates uncertainty given the local model structure.


**Output:**
```
PhyBaSE d-separation Tests
==========================

           Test Parameter Estimate LowerCI UpperCI Indep P_approx_0
 C _||_ A | {B}     betaA   -0.090  -0.724   0.518   Yes      0.776

Joint P(all tests ≈ 0) = 0.776

Legend:
  Indep: 'Yes' = Conditionally Independent, 'No' = Dependent (based on 95% CI)
  P(≈0): Bayesian probability that effect crosses zero (0-1 scale)
  Joint: Probability that ALL tests simultaneously support independence

Note: For d-separation, we expect high P(≈0) and Joint values (close to 1).
```

The `P(≈0)` gives you a Bayesian measure of how plausible independence is for each individual test, while the `Joint` probability tells you how often ALL tests simultaneously support the model structure.

## Latent Variables

PhyBaSE can handle **unobserved (latent) variables** using two different approaches:

### Approach 1: MAG (Correlations) - **Default**

The **Maximal Ancestral Graph (MAG)** approach marginalizes latent variables and models the **induced correlations** they create between observed variables.

```{r latent_mag, eval=FALSE}
# Suppose we have a latent variable L that affects both X and Y
# L -> X, L -> Y (L is unmeasured)

equations <- list(
    X ~ L,
    Y ~ L
)

fit_mag <- phybase_run(
    data = data_list,
    tree = tree,
    equations = equations,
    latent = "L",
    latent_method = "correlations", # Default, can omit
    n.iter = 10000
)

# Check induced correlations
fit_mag$induced_correlations
# [[1]]
# [1] "X" "Y"

# The correlation parameter rho_X_Y is estimated
summary(fit_mag)
```

**How it works**:
1. Converts your DAG to a MAG
2. Identifies bidirected edges `X <-> Y` from latent common causes
3. Models correlations using correlated residuals in JAGS

**Advantages**: Consistent with Shipley's d-separation framework, no need to worry about latent variable identification.

### Approach 2: Explicit Latent Variables

Alternatively, you can model latents as **actual JAGS nodes** and estimate the structural paths from latents to observed variables.

```{r latent_explicit, eval=FALSE}
fit_explicit <- phybase_run(
    data = data_list,
    tree = tree,
    equations = list(X ~ L, Y ~ L),
    latent = "L",
    latent_method = "explicit", # Model L as a node
    n.iter = 10000
)

# Estimates betaX_L and betaY_L
summary(fit_explicit)
```

**Advantages**: More flexible, allows estimation of latent -> observed paths.

**Disadvantages**: Requires careful consideration of identification and scaling.

**Note**: `phybaseR` automatically standardizes latent variables (fixes variance to 1) when using the explicit approach. This ensures identification and makes path coefficients interpretable as standardized effects. This is consistent with the recommendation to standardize all variables before running PhyBaSE models.

### Understanding Identification Issues

When using the **explicit approach**, latent variables have no inherent scale, leading to **identification problems** where multiple parameter combinations fit the data equally well.

**Example**: Consider `L -> X` and `L -> Y`:
- You could double the scale of `L` and halve both path coefficients → **same predictions**
- JAGS may struggle to converge or produce unreliable estimates

**Why MAG avoids this**: The MAG approach only estimates the **correlation** `rho_X_Y` induced by `L`, which is scale-invariant. You don't need to worry about the scale of `L` or its individual paths.

**How phybaseR handles this**: When using `latent_method = "explicit"`, `phybaseR` automatically **standardizes latent variables** by fixing their variance to 1 (`tau_L <- 1` in the JAGS model). This:
- Ensures the model is identified (no scale ambiguity)
- Makes path coefficients interpretable as standardized effects
- Is consistent with the recommendation to standardize all variables

**Example**: With `L -> X` and `L -> Y`:
- `L` has variance = 1 (standardized)
- `betaX_L = 0.8` means "1 SD change in L → 0.8 SD change in X"
- Path coefficients are directly comparable

### Recommendations

- **Default to MAG (correlations)**: Safer, more interpretable, consistent with d-separation testing
- **Use explicit sparingly**: Only when you have good reasons and understand the identification constraints
- **For model comparison**: Use MAG method when comparing models with WAIC/DIC (see below)

### Model Comparison with Latent Variables

> **IMPORTANT**: Do not use WAIC/DIC to compare explicit latent variable models with models that don't include latent variables.

**Why this matters**:

When using `latent_method = "explicit"`, the latent variable values `L[1:N]` (one per species) are treated as **model parameters** in the WAIC/DIC calculation. This means:

```r
# Model 1: No latent (e.g., BR and BM are independent predictors)
fit_no_latent <- phybase_run(
  equations = list(S ~ BM, G ~ BR, L ~ BR),
  WAIC = TRUE
)
# WAIC calculated on observed data: S, G, L

# Model 2: Explicit latent
fit_explicit <- phybase_run(
  equations = list(BR ~ Lat, BM ~ Lat, S ~ BM, G ~ BR, L ~ BR),
  latent = c("Lat"),
  latent_method = "explicit",
  WAIC = TRUE
)
# WAIC calculated on: S, G, L, BR, BM, + N latent Lat[i] values
```

**The problem**: Model 2 has effectively **N more "data points"** (the latent values) in its likelihood, making WAIC non-comparable. Lower WAIC doesn't necessarily mean better fit—it might just reflect different effective sample sizes.

**Solution: Use MAG for model comparison**

```r
# Safe comparison: Both use MAG
fit_independent <- phybase_run(
  equations = list(S ~ BM, G ~ BR, L ~ BR),
  # BR and BM independent
  WAIC = TRUE
)

fit_with_latent <- phybase_run(
  equations = list(BR ~ Lat, BM ~ Lat, S ~ BM, G ~ BR, L ~ BR),
  latent = c("Lat"),
  latent_method = "correlations",  # MAG (default)
  WAIC = TRUE
)

# Valid comparison!
fit_independent$WAIC["waic", "Estimate"]  # Higher WAIC
fit_with_latent$WAIC["waic", "Estimate"]  # Lower WAIC → latent structure supported
```

**Why MAG works**: The MAG approach marginalizes out latent variables, so WAIC is calculated **only on observed data** (S, G, L, BR, BM) in both models. This makes the information criteria directly comparable.

**When explicit method is appropriate**:
- Theoretical interest in **specific path coefficients** from latent to observed (e.g., `beta_BR_Lat`)
- **NOT** for routine model comparison

**Summary**:
- ✅ **MAG vs MAG**: WAIC/DIC comparable
- ✅ **MAG vs No latent**: WAIC/DIC comparable  
- ❌ **Explicit vs MAG/No latent**: WAIC/DIC **not** comparable

### Why WAIC Instead of LOO-CV?

**WAIC (Widely Applicable Information Criterion)** is the recommended approach for model comparison in `phybaseR` rather than LOO-CV (Leave-One-Out Cross-Validation).

**Why?**

In phylogenetic models, observations are **not independent** - they're connected through the phylogenetical covariance matrix. This creates technical challenges for LOO:

1. **Pointwise likelihood is not well-defined**: The likelihood for species `i` depends on ALL other species through phylogenetic correlation
2. **Conditional likelihoods are complex**: Computing `p(y_i | y_{-i})` requires N separate covariance matrix inversions
3. **WAIC is already available**: JAGS provides WAIC efficiently via the `dic` module

**Best practice**:
```r
# Use WAIC for model comparison
fit1 <- phybase_run(..., WAIC = TRUE)
fit2 <- phybase_run(..., WAIC = TRUE)

# Compare
fit1$WAIC  # Lower is better
fit2$WAIC
```

**Note**: LOO-CV functionality may be added in future versions if there's demand for it.

### Limitations

- MAG approach currently supports **pairwise correlations** only
- Explicit approach requires constraints for identification with complex latent structures


## Generalized Covariance Structures

While PhyBaSE was originally designed for phylogenetic models, `phybaseR` now supports arbitrary covariance structures. You can specify the covariance structure using the `structure` argument (which replaces `tree` in newer versions).

### 1. Independent SEMs (Non-Phylogenetic)

To run a standard Bayesian SEM without any phylogenetic or spatial structure, simply set `structure = NULL`. This is the default if `structure` or `tree` are not provided.

```{r independent, eval=FALSE}
fit_indep <- phybase_run(
    data = data_list,
    structure = NULL, # Independent model
    equations = equations
)
```

In this mode, `phybaseR` assumes independent residuals for all variables (Gaussian, Binomial, Multinomial, etc.).

### 2. Spatial or Custom Covariance

You can provide a custom covariance or precision matrix (e.g., spatial connectivity) via the `structure` argument. The matrix must be $N \times N$ with row/column names matching your data.

```{r spatial, eval=FALSE}
# Create a spatial precision matrix
spatial_prec <- solve(exp(-dist_matrix / range))

fit_spatial <- phybase_run(
    data = data_list,
    structure = spatial_prec, # Pass matrix directly
    equations = equations
)
```

### 3. Animal Models (Pedigree)

For quantitative genetics (Animal Models), you can pass the inverse additive genetic relationship matrix ($A^{-1}$) derived from a pedigree.

```{r animal, eval=FALSE}
# Using MCMCglmm to get A-inverse
library(MCMCglmm)
inv_A <- inverseA(pedigree)$Ainv

fit_animal <- phybase_run(
    data = data_list,
    structure = as.matrix(inv_A),
    equations = equations
)
```

### 4. Multiple Additive Structures (Phylo + Spatial)

You can model multiple additive random effects (e.g., Phylogenetic + Spatial) by passing a named list to `structure`. The model will estimate separate variance components (`sigma_phylo`, `sigma_spatial`) for each structure.

```{r multi_struct, eval=FALSE}
fit_multi <- phybase_run(
    data = data_list,
    structure = list(
        phylo = tree,
        spatial = spatial_cov_matrix
    ),
    equations = equations
)
```

> **Note:** Currently, support for multiple additive structures is optimized for **Gaussian** response variables and predictor imputation. 
> 
> **Limitation:** Non-Gaussian families (Binomial, Multinomial, Ordinal) currently support only a **single** covariance structure. If you need to use these families, please ensure `structure` contains only one element (e.g., the phylogeny). Support for multiple structures in non-Gaussian models is planned for a future release.


## Random Effects Models (GLMMs)

`phybaseR` supports **Linear Mixed Models (LMMs)** and **Generalized Linear Mixed Models (GLMMs)** using `lmer`-style syntax. This allows you to include random intercepts for grouping factors (e.g., species, site, year) alongside phylogenetic effects.

### Syntax

To add a random intercept for a group, use `(1|Group)` inside your model equation:

```r
equations = list(Y ~ X + (1|Site))
```

### Example: Gaussian Random Intercept

```r
# Data with grouping factor 'Site'
data_glmm <- data.frame(
    Y = rnorm(100),
    X = rnorm(100),
    Site = sample(LETTERS[1:5], 100, replace = TRUE)
)

fit_glmm <- phybase_run(
    equations = list(Y ~ X + (1|Site)),
    data = data_glmm,
    n.chains = 2,
    n.iter = 1000
)

summary(fit_glmm)
```

**Output Interpretation**:
- `sigma_Y_Site`: Standard deviation of the random effect (between-site variation).
- `sigma_Y_res`: Residual standard deviation (within-site variation).

### Multiple Random Effects

You can include multiple additive random effects in the same equation:

```r
equations = list(Y ~ X + (1|Site) + (1|Year))
```

This estimates separate variance components for `Site` (`sigma_Y_Site`) and `Year` (`sigma_Y_Year`).

### GLMMs (Non-Gaussian)

Random effects work seamlessly with all supported distributions (Poisson, Binomial, etc.), allowing you to fit phylogenetic GLMMs.

**Example: Poisson GLMM with Overdispersion**

```r
# Poisson count data with site-level random effects
fit_pois_glmm <- phybase_run(
    equations = list(Count ~ Temp + (1|Site)),
    data = data_counts,
    distribution = list(Count = "poisson")
)
```

In this model:
- `alphaCount`: Global intercept
- `beta_Count_Temp`: Effect of temperature
- `sigma_Count_Site`: Variation between sites
- `sigma_Count_res`: Overdispersion (residual variation beyond Poisson expectation)

### Notes
- **Random Slopes**: Currently, only random intercepts `(1|Group)` are supported. Random slopes `(X|Group)` are not yet implemented and will default to a random intercept with a warning.
- **Optimization**: Random effects models use the optimized JAGS implementation by default for speed.



### Global Random Effects

If you want to apply the same random effect structure to **all** equations in your model (e.g., a block effect or random intercept for Site across all species), you can use the `random` argument in `phybase_run`. This is more convenient than adding `(1|Group)` to every equation and ensures consistent handling in d-separation tests.

```r
fit_global <- phybase_run(
    equations = list(
        Y1 ~ X1,
        Y2 ~ Y1 + X2
    ),
    data = data_glmm,
    random = ~ (1|Site), # Applies (1|Site) to BOTH Y1 and Y2
    n.chains = 2,
    n.iter = 1000
)
```

**Note:** `phybaseR` automatically detects overlapping random terms. If you specify `(1|Site)` in an equation AND in the global `random` argument, it will be handled correctly (deduplicated) to avoid double-counting.

### Hierarchical Data: Handling Multi-Level Variables

**Problem**: When variables are measured at different hierarchical levels (e.g., site-year vs individual), storing them in one dataset with replicated values can cause **sample size inflation** when testing relationships between higher-level variables.

**Example scenario**:
- Individual-level measurements: `weight`, `age` (20 unique individuals)
- Site-year measurements: `temperature`, `rainfall` (4 unique site-year combinations, replicated across individuals)

When testing `temperature ~ rainfall` with replicated data, the model incorrectly sees 20 observations instead of 4.

**Solution**: phybaseR now supports hierarchical data structures automatically!

```r
# Individual-level data
individual_data <- data.frame(
  individual_id = 1:20,
  site = rep(c("A", "B"), each = 10),
  year = rep(c(2020, 2021), 10),
  weight = rnorm(20, 50, 10),
  age = rnorm(20, 5, 2)
)

# Site-year level data (only 4 unique combinations!)
site_year_data <- data.frame(
  site = c("A", "A", "B", "B"),
  year = c(2020, 2021, 2020, 2021),
  temperature = c(15, 16, 17, 18),
  rainfall = c(800, 850, 900, 950)
)

# Specify hierarchical structure
fit <- phybase_run(
  data = list(
    individual = individual_data,
    site_year = site_year_data
  ),
  levels = list(
    individual = c("weight", "age"),
    site_year = c("temperature", "rainfall")
  ),
  hierarchy = "site_year > individual",
  link_vars = c("site", "year"),
  equations = list(
    weight ~ age + temperature,
    age ~ rainfall
  ),
  dsep = TRUE
)
```

**How it works**:
- phybaseR automatically joins datasets for the main model (20 observations)
- For d-separation tests, each test uses the appropriate dataset:
  - `weight _||_ rainfall | age, temperature` → 20 observations (needs individual level)
  - `temperature _||_ rainfall | ` → 4 observations (site-year only!)
- Sample sizes are correct for all tests

**Key parameters**:
- `levels`: Maps variables to hierarchical levels
- `hierarchy`: Specifies nesting (e.g., "site_year > individual")
- `link_vars`: Variables that link levels (e.g., site, year)

